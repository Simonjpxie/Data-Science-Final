# The Chinese University of Hong Kong
# Econ 5181 Data Science for Economists
# Examination, 2024 Spring

# Name: XIE, Jiapeng
# Student ID: 

rm(list = ls())

# Question 1

# Import a CSV file from a URL. The code is from "data_download_test" provided by professor.
url <- "https://raw.githubusercontent.com/zhentaoshi/Econ5821/master/data_example/3_National_Greenhouse_Gas_Emissions_Inventories_and_Implied_National_Mitigation_Nationally_Determined_Contributions_Targets.csv"
d0 <- read.csv(url, header = TRUE)
head(d0)

# Question 1(a)
# Count the number of unique ISO2 codes
# The code was generated by GPT4
N <- length(unique(d0$ISO2))

print(N)

# Keep rows where ISO2 is not missing or empty.
# The code was generated by GPT4
d1 <- subset(d0, !is.na(ISO2) & ISO2 != "")

# Question 1(b)

# Check whether the name of "gap type" exists in the data set
names(d1)

# There is only a column named "Gas.Type" in the data set containing "Carbon dioxide"
# So, we use "Gas.Type" instead of "gap type"
# The code was generated by GPT4
d1_filtered <- subset(d1, Gas.Type == "Carbon dioxide")

# There are so many NA values in this data set.
# In order to analyse the following questions conveniently,
# replace NA values with 0 across all columns

# The code was generated by GPT4
library(dplyr)
d1_filtered <- d1_filtered %>% mutate(across(everything(), ~replace(., is.na(.), 0)))

# Question 1(c)

# Part 1: Compute the correlation coefficient of all available years of 
# “Industry == 1. Energy” and “Industry == 4. Land-use, land-use change and forestry”.

# Filter for the two industries
library(tidyr)
energy <- d1_filtered %>% filter(Industry == "1. Energy")

# We need to pivot the data to have years as columns (panel format)

# GPT 4 generates the following codes:
# # Load necessary libraries 
# library(tidyverse) 
# # Read the data 
# energy_df <- read.csv("path_to_your_file/energy.csv") 
# # Convert wide data to long format (panel data) 
# energy_long <- energy_df %>% 
  # pivot_longer(cols = starts_with("X"), names_to = "Year", values_to = "Value") %>% 
  # mutate(Year = parse_number(Year)) # Convert Year to a numeric value 

# Land use data set is unavailable from 1970 to 1989
# Both energy and and land use data sets are unavailable from 2023 to 2030
# So I filter years from 1970 to 1989, and 2023 to 2030

# Here are codes I modify:
library(plm)
library(tidyverse)

energy_long <- energy %>%
  pivot_longer(cols = starts_with("X"), names_to = "Year", values_to = "Value") %>%
  mutate(Year = parse_number(Year)) %>%
  filter(!(Year >= 1970 & Year <= 1989), !(Year >= 2023 & Year <= 2030))

# I imitates the GPT4 sample codes, applying them similarly for land use
land_use <- d1_filtered %>% filter(Industry == "4. Land-use, land-use change and forestry")

land_use_long <- land_use %>%
  pivot_longer(cols = starts_with("X"), names_to = "Year", values_to = "Value") %>%
  mutate(Year = parse_number(Year)) %>%
  filter(!(Year >= 1970 & Year <= 1989), !(Year >= 2023 & Year <= 2030))

# Combine two data sets into one

# GPT4 generates:
# combined_data <- merge(data1, data2, by = "id", all = TRUE) 

# I modified:
combined_data <- merge(land_use_long, energy_long, by=c("Country", "ISO2", "Year"))

# Then, filter data set and make it clear.

# GPT4 generates:
# # Assuming 'data_filtered' is your filtered dataset 
# library(dplyr) 
# correlation_results <- data_filtered %>% 
  # group_by(ISO2) %>% 
  # filter(sd(Value1) != 0 & sd(Value2) != 0) %>% # Ensure there is variation in both sets of values 
  # summarise(Correlation = cor(Value1, Value2, use = "complete.obs")) 

# print(correlation_results) 

# I modified:
library(dplyr)

correlation_results <- combined_data %>%
  group_by(ISO2) %>%
  filter(sd(Value.x) != 0 & sd(Value.y) != 0) %>% # Ensure there is variation in both sets of values
  summarise(Correlation = cor(Value.x, Value.y, use = "complete.obs"))

print(correlation_results)

# Now, proceed to plot the histogram with ggplot2 as previously described
# These codes are generated by GPT4
library(ggplot2)

ggplot(correlation_results, aes(x = Correlation)) +
  geom_histogram(binwidth = 0.1, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Histogram of Correlation Coefficients",
       x = "Correlation Coefficient",
       y = "Frequency")

rm(energy_long, land_use_long, combined_data, correlation_results)

# Question 1(d)

# I imitated codes from GPT4 previously, and wrote codes below:
# First, filter years from 2023 to 2030

# Energy
energy_long2 <- energy %>%
  pivot_longer(cols = starts_with("X"), names_to = "Year", values_to = "Value") %>%
  mutate(Year = parse_number(Year)) %>%
  filter(!(Year >= 2023 & Year <= 2030))

# Industrial Processes and Product Use
indus_process <- d1_filtered %>% filter(Industry == "2. Industrial Processes and Product Use")

indus_process_long2 <- indus_process %>%
  pivot_longer(cols = starts_with("X"), names_to = "Year", values_to = "Value") %>%
  mutate(Year = parse_number(Year)) %>%
  filter(!(Year >= 2023 & Year <= 2030))

# Agriculture
agriculture <- d1_filtered %>% filter(Industry == "3. Agriculture")

agriculture_long2 <- agriculture %>%
  pivot_longer(cols = starts_with("X"), names_to = "Year", values_to = "Value") %>%
  mutate(Year = parse_number(Year)) %>%
  filter(!(Year >= 2023 & Year <= 2030))

# Land Use
land_use_long2 <- land_use %>%
  pivot_longer(cols = starts_with("X"), names_to = "Year", values_to = "Value") %>%
  mutate(Year = parse_number(Year)) %>%
  filter(!(Year >= 2023 & Year <= 2030))

# Waste
waste <- d1_filtered %>% filter(Industry == "5. Waste")

waste_long2 <- waste %>%
  pivot_longer(cols = starts_with("X"), names_to = "Year", values_to = "Value") %>%
  mutate(Year = parse_number(Year)) %>%
  filter(!(Year >= 2023 & Year <= 2030))

# Other 
other <- d1_filtered %>% filter(Industry == "6. Other")

other_long2 <- other %>%
  pivot_longer(cols = starts_with("X"), names_to = "Year", values_to = "Value") %>%
  mutate(Year = parse_number(Year)) %>%
  filter(!(Year >= 2023 & Year <= 2030))

# Merge all data set
all_datasets_df <- bind_rows(energy_long2, indus_process_long2, agriculture_long2, land_use_long2, waste_long2, other_long2)

rm(energy, indus_process, agriculture, land_use, waste, other)
rm(energy_long2, indus_process_long2, agriculture_long2, land_use_long2, waste_long2, other_long2)

# Transform the dataset to panel data format
# The codes are generated by GPT4:
library(tidyverse)

wider_df <- all_datasets_df %>%
  # Optional: Filter or select specific columns if necessary
  select(Country, Year, Industry, Value) %>%
  # Spread the 'Industry' values into separate columns with corresponding 'Value'
  pivot_wider(names_from = Industry, values_from = Value, values_fill = list(Value = 0))


# Filter the dataset for China, P.R.: Mainland
china_df <- filter(wider_df, Country == "China, P.R.: Mainland")

# Select relevant columns and calculate total CO2 emissions
# The codes are what I imitates from previous codes generated by GPT4
china_df <- china_df %>%
  select(Year, `1. Energy`, `2. Industrial Processes and Product Use`, `3. Agriculture`, `4. Land-use, land-use change and forestry`, `5. Waste`, `6. Other`) %>%
  mutate(Total_CO2_Emissions = `1. Energy` + `2. Industrial Processes and Product Use` + `3. Agriculture` + `4. Land-use, land-use change and forestry` + `5. Waste` + `6. Other`)

# Aggregate total CO2 emissions by year in case of any duplicates
# These codes are generated by GPT4
china_yearly_co2 <- china_df %>%
  group_by(Year) %>%
  summarise(Total_CO2_Emissions = sum(Total_CO2_Emissions))

head(china_yearly_co2)

# Plotting
# These codes are generated by GPT4
ggplot(data = china_yearly_co2, aes(x = Year, y = Total_CO2_Emissions)) +
  geom_line(color = "blue") +
  geom_point(color = "green") +
  theme_minimal() +
  labs(title = "Total CO2 Emissions in China, P.R.: Mainland (1970-2022)",
       x = "Year",
       y = "Total CO2 Emissions (Million metric tons of CO2 equivalent)")

rm(all_datasets_df, china_df,china_yearly_co2, wider_df)





# Question 2

# Question 2(a)
# Select relevant columns and calculate total CO2 emissions

library(dplyr)
library(tidyverse)

# Filter rows of "Baseline Energy CO2 emissions"
# The codes are generated by GPT4
filtered_d1 <- d1 %>%
  filter(Indicator == "Baseline Energy CO2 emissions")

# Transform the data set into panel data
# Remove NA values to find the latest non-NA value
# I imitated previous codes from GPT4 to write them:
data_long <- filtered_d1 %>%
  pivot_longer(cols = starts_with("X"), names_to = "Year", values_to = "CO2_Emissions") %>%
  filter(!is.na(CO2_Emissions)) # 

# Group by country and summarize
# I imitated previous codes from GPT4 to write them:
Baseline_Energy_CO2_Emissions <- data_long %>%
  group_by(Country) %>%
  summarize(Baseline_Energy_CO2_Emissions = last(CO2_Emissions, order_by = Year))

# Sort the data by CO2 emissions from high to low

# GPT generated codes here:
# sorted_df <- df %>%
#   arrange(desc(df))

# I modify it here:
sorted_emissions <- Baseline_Energy_CO2_Emissions %>%
  arrange(desc(Baseline_Energy_CO2_Emissions))

print(sorted_emissions)

rm(filtered_d1, data_long, sorted_emissions)

# Question 2(b)

# Filter rows of "IMF estimated CO2 emissions under a Business as Usual assumption"
# I imitated previous codes from GPT4
d2_filtered <- d1 %>%
  filter(Indicator == "IMF estimated CO2 emissions under a Business as Usual assumption")

# Tranform into panel data format
# Remove NA values to find the latest non-NA value
# I imitated previous codes from GPT4
data_long2 <- d2_filtered %>%
  pivot_longer(cols = starts_with("X"), names_to = "Year", values_to = "CO2_Emissions") %>%
  filter(!is.na(CO2_Emissions)) 

# Some errors happened when running previuos codes
# I copied errors and asked for GPT4
# Here are codes GPT4 generated:

# Convert the Year column to a numeric type, removing the 'X' prefix
data_long2$Year <- as.numeric(gsub("X", "", data_long2$Year))

# Filter "IMF estimated CO2 emissions under a Business as Usual assumption" in 2030
data_long2 <- data_long2 %>%
  filter(Year == 2030)

# Merge the datasets on the 'Country' column
merged_df <- merge(Baseline_Energy_CO2_Emissions, data_long2, by="Country")

# Fit the linear regression model
model <- lm(CO2_Emissions ~ Baseline_Energy_CO2_Emissions, data=merged_df)

# Summary of the model to report estimates and standard errors
summary(model)

# Calculate 90% confidence intervals for alpha and beta
confint(model, level=0.90)

rm(data_long2, merged_df, model)

# Question 2(c)

# Filter rows of "IMF estimated CO2 emissions under a Business as Usual assumption"
IMF_estimates <- d1 %>%
  filter(Indicator == "IMF estimated CO2 emissions under a Business as Usual assumption")

# Transform into panel data format
# Remove NA values to find the latest non-NA value
IMF_estimates <- IMF_estimates %>%
  pivot_longer(cols = starts_with("X"), names_to = "Year", values_to = "CO2_Emissions") %>%
  filter(!is.na(CO2_Emissions)) 

# Convert the Year column to a numeric type, removing the 'X' prefix
# I imitated previous codes from GPT4
IMF_estimates$Year <- as.numeric(gsub("X", "", IMF_estimates$Year))

head(IMF_estimates)

# Question 2(d)

library(readxl)
library(dplyr)

# Import data from url
url <- "https://raw.githubusercontent.com/zhentaoshi/Econ5821/master/data_example/WEOOct2023all.xlsx"

# GPT4 generated codes below:

# Download the Excel file, because read_excel  cannot load file on the url
download.file(url, destfile = "WEOOct2023all.xlsx")

# Read Excel file
weo_data <- read_excel("WEOOct2023all.xlsx")

# There some warnings after I read the Excel file directly
# I asked GPT4. Here are codes GPT4 gave:

# Custom function to replace '--' and 'n/a' with NA, handling both numeric and character columns
replace_values <- function(x) {
  if (is.numeric(x)) {
    x <- as.character(x)  # Convert numeric to character for replacement
  }
  x <- ifelse(x == '--' | x == 'n/a', NA, x)
  if (is.character(x)) {
    x <- type.convert(x, as.is = TRUE)  # Convert back to original type if possible
  }
  return(x)
}

weo_data <- weo_data %>%
  mutate(across(everything(), replace_values))

# Filter for population at first
population <- weo_data %>%
  filter(`Subject Descriptor` == "Population")

# Filter for population in 2023 now
population_2023 <- population %>% select(`WEO Country Code`, ISO, Country, `Subject Descriptor`, `2023`)

# Transfer dataset to panel format
population_2023 <- population_2023 %>%
  pivot_longer(cols = `2023`,
               names_to = "Year",
               values_to = "Value")

print(population_2023)

# Question 2(e)

# Combine two data sets
new_combined <- merge(IMF_estimates, population_2023, by = "Country")

# There are some errors when I ran the codes following
# I asked GPT4 how to solve them

# GPT4 generates codes like this:
# Ensure CO2_Emissions and Value are numeric
new_combined$CO2_Emissions <- as.numeric(as.character(new_combined$CO2_Emissions))
new_combined$Value <- as.numeric(as.character(new_combined$Value))

# Now, calculate the emission per capita
# I imitated previous codes from GPT4
new_combined <- new_combined %>%
  mutate(Emission_Per_Capita = CO2_Emissions / Value)

# Select relevant columns for the new data set
emission_per_capita <- select(new_combined, Country, Year.x, Emission_Per_Capita)

# Rename columns for clarity
# This is suggested by GPT4 when I asked for errors
colnames(emission_per_capita)[colnames(emission_per_capita) == "Year.x"] <- "Year"

# I'm not sure why the new combined data is not in ascending order of the year
# So, I order the data by Country and Year again
emission_per_capita <- emission_per_capita %>% arrange(Country, Year)

head(emission_per_capita)

# Question 2(f)

library(ggplot2)
library(dplyr)

# I asked the question for GPT4 directly
# Here are codes generated by GPT4:

# Create a list to store plots
plot_list <- list()

# Generate a histogram for each year from 2023 to 2030
for(year in 2023:2030) {
  # Filter data for the year and remove rows with non-finite values in Emission_Per_Capita
  data_for_year <- filter(emission_per_capita, Year == year) %>%
    filter(!is.na(Emission_Per_Capita) & !is.infinite(Emission_Per_Capita))
  
  # Create the histogram using ggplot
  p <- ggplot(data_for_year, aes(x=Emission_Per_Capita)) +
    geom_histogram(bins=20, fill="skyblue", color="black") +
    theme_minimal() +
    labs(title=paste("Emission Per Capita in", year),
         x="Emission Per Capita",
         y="Frequency")
  
  # Add the plot to the list
  plot_list[[as.character(year)]] <- p
}

# Arrange the plots in a 4x2 grid
require(gridExtra)
grid.arrange(grobs=plot_list, ncol=2)


